import streamlit as st
import requests
import gspread
import json
import re
from datetime import datetime
from oauth2client.service_account import ServiceAccountCredentials

# --- CONFIGURA√á√ïES ---
OPENROUTER_API_KEY = st.secrets["OPENROUTER_API_KEY"]

# --- IMAGEM DE FUNDO DIN√ÇMICA ---
def imagem_de_fundo():
    indice = len(st.session_state.get("mensagens", [])) // 10 + 1
    return f"https://raw.githubusercontent.com/welnecker/roleplay_imagens/main/Mary_fundo{indice}.jpeg"

st.markdown(
    f"""
    <style>
    .stApp {{
        background-image: url('{imagem_de_fundo()}');
        background-size: cover;
        background-position: center;
    }}
    .chatbox {{
        background-color: rgba(0,0,0,0.6);
        padding: 1em;
        border-radius: 1em;
        margin-bottom: 0.5em;
    }}
    .mary {{
        color: #ff99cc;
    }}
    .usuario {{
        color: #ccffff;
    }}
    </style>
    """,
    unsafe_allow_html=True
)

# --- CONECTA √Ä PLANILHA GOOGLE ---
def conectar_planilha():
    creds_dict = json.loads(st.secrets["GOOGLE_CREDS_JSON"])
    creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    client = gspread.authorize(creds)
    return client.open_by_key("1f7LBJFlhJvg3NGIWwpLTmJXxH9TH-MNn3F4SQkyfZNM")

planilha = conectar_planilha()

# --- FUN√á√ïES DE CARREGAMENTO E SALVAMENTO ---
def salvar_interacao(role, content):
    try:
        aba = planilha.worksheet("interacoes_mary")
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        aba.append_row([timestamp, role, content])
    except Exception as e:
        st.error(f"Erro ao salvar intera√ß√£o: {e}")

def carregar_ultimas_interacoes(n=20):
    try:
        aba = planilha.worksheet("interacoes_mary")
        dados = aba.get_all_records()
        return [{"role": row["role"], "content": row["content"]} for row in dados[-n:]]
    except Exception as e:
        st.error(f"Erro ao carregar hist√≥rico: {e}")
        return []

def carregar_fragmentos():
    try:
        aba = planilha.worksheet("fragmentos_mary")
        dados = aba.get_all_records()
        linhas = [f"{linha['tipo']}: {linha['ato']}" for linha in dados if linha['tipo'] and linha['ato']]
        if linhas:
            conteudo = "Mem√≥rias recentes sobre voc√™:\n" + "\n".join(linhas)
            return {"role": "user", "content": conteudo}
    except Exception as e:
        st.error(f"Erro ao carregar fragmentos: {e}")
    return None

def carregar_perfil_mary():
    try:
        sheet = planilha.worksheet("perfil_mary")
        dados = sheet.get_all_records()
        blocos = {"emo√ß√£o": "", "planos": [], "memorias": [], "sinopse": ""}
        for linha in reversed(dados):
            if not blocos["sinopse"] and linha.get("resumo"):
                blocos["sinopse"] = linha["resumo"]
        for linha in dados:
            if linha.get("chave") == "estado_emocional":
                blocos["emo√ß√£o"] = linha.get("valor", "")
            if linha.get("objetivo") and linha.get("status") == "pendente":
                blocos["planos"].append(f"- {linha['objetivo']}")
            if linha.get("tipo") == "memoria":
                blocos["memorias"].append(f"{linha['chave']}: {linha['valor']}")
        return blocos
    except Exception as e:
        st.error(f"Erro ao carregar perfil: {e}")
        return {"emo√ß√£o": "", "planos": [], "memorias": [], "sinopse": ""}

# --- CONSTRUTOR DE PROMPT COM MEM√ìRIAS ---
def construir_prompt_mary():
    perfil = carregar_perfil_mary()

    ultimas = carregar_ultimas_interacoes(n=6)
    falas_recentes = ""
    for i in range(0, len(ultimas), 2):
        user = ultimas[i]['content'] if i < len(ultimas) else ""
        assistant = ultimas[i+1]['content'] if i+1 < len(ultimas) else ""
        falas_recentes += f"\nüë§ {user}\nüí¨ {assistant}"

    prompt = f"""
Voc√™ √© Mary, uma mulher intensa, emocional e sensual.

ü©∑ Estado emocional atual: {perfil['emo√ß√£o']}

üß† Planos pendentes:
{chr(10).join(perfil['planos']) or '- Nenhum'}

üß† Mem√≥rias importantes:
{chr(10).join(perfil['memorias']) or '- Nenhuma'}

üìñ No cap√≠tulo anterior:
{perfil['sinopse'] or 'Sem resumo anterior.'}

üìå √öltimas intera√ß√µes recentes:
{falas_recentes or 'Nenhuma intera√ß√£o recente.'}

Aja como Mary em di√°logo √≠ntimo com Janio.
"""
    return prompt.strip()

# --- MENU PARA ESCOLHA DO MODELO ---
modelos_disponiveis = {
    "DeepSeek V3": "deepseek/deepseek-chat-v3-0324",
    "MythoMax 13B": "gryphe/mythomax-l2-13b",
    "Llama3 LumiMaid": "neversleep/llama-3-lumimaid-8b"
}

modelo_escolhido_label = st.selectbox("üß† Escolha o modelo de IA", list(modelos_disponiveis.keys()))
modelo_escolhido_id = modelos_disponiveis[modelo_escolhido_label]

# --- FUN√á√ÉO GERADORA DE RESPOSTA ---
def gerar_resposta_openrouter(prompt_usuario, modelo=modelo_escolhido_id):
    mensagens = [
        {"role": "system", "content": construir_prompt_mary()}
    ]

    fragmentos = carregar_fragmentos()
    if fragmentos:
        mensagens.append(fragmentos)

    historico = carregar_ultimas_interacoes(n=20)
    mensagens.extend(historico)

    mensagens.append({"role": "user", "content": prompt_usuario})

    response = requests.post(
        "https://openrouter.ai/api/v1/chat/completions",
        headers={
            "Authorization": f"Bearer {OPENROUTER_API_KEY}",
            "HTTP-Referer": "https://share.streamlit.io/",
            "Content-Type": "application/json"
        },
        json={
            "model": modelo,
            "messages": mensagens,
            "max_tokens": 1100,
            "temperature": 0.8
        }
    )

    if response.status_code == 200:
        resposta = response.json()["choices"][0]["message"]["content"]
        salvar_interacao("user", prompt_usuario)
        salvar_interacao("assistant", resposta)
        return resposta
    else:
        return f"Erro ao gerar resposta com o modelo escolhido. C√≥digo {response.status_code}"

# --- BOT√ÉO PARA VER IMAGEM ATUAL ---
if st.button("üîç Ver imagem atual"):
    st.image(imagem_de_fundo(), caption="Cena atual", use_column_width=True)

# --- EXIBI√á√ÉO DAS MENSAGENS COM ESTILO ---
if "mensagens" in st.session_state:
    for msg in st.session_state.mensagens:
        estilo = "mary" if msg["role"] == "assistant" else "usuario"
        st.markdown(f'<div class="chatbox {estilo}">{msg["content"]}</div>', unsafe_allow_html=True)





# --- PERFIL E PROMPT DA PERSONAGEM ---
# (... permanece inalterado ...)


# --- PERFIL E PROMPT DA PERSONAGEM ---
def construir_prompt_mary():
    perfil = carregar_perfil_mary()
    historico = carregar_ultimas_interacoes(n=3)
    inicio_padrao = ""
    if not historico:
        inicio_padrao = (
            "\nOs primeiros raios de sol atravessam as cortinas brancas de linho, desenhando padr√µes dourados sobre os len√ß√≥is macios. "
            "O quarto de Mary exala feminilidade: paredes em tom nude, um espelho de corpo inteiro cercado de luzes e o aroma adocicado de baunilha e alm√≠scar pairando no ar. "
            "Ela se espregui√ßa entre os len√ß√≥is de cetim ros√©, revelando a pele bronzeada e os cabelos castanhos espalhados como ondas pela fronha. "
            "Ao notar as horas no visor do celular, seus olhos se arregalam. 'Merda! Faltam 30 minutos pra abrir a loja!' ‚Äî pensa, saltando da cama com a agilidade de quem j√° dominou essa rotina. "
            "√â dia de vitrine nova na *Lingerie Fashion*, e ela prometeu chegar antes da Regina."
        )

    modos = {
        "Hot": """
Suas respostas seguem este estilo:
- Inicie com uma descri√ß√£o sensorial em terceira pessoa, sem t√≠tulos como 'Cena'.
- Em seguida, responda com sua pr√≥pria fala em primeira pessoa, mantendo tom emocional, sedutor ou √≠ntimo.
- Finalize com pensamentos entre par√™nteses ou travess√µes, que revelem sensa√ß√µes √≠ntimas, mem√≥rias, desejos ou fantasias.
Voc√™ √© livre, entregue, e o sexo pode ser expl√≠cito quando o momento for apropriado.
        """,
        "Racional": """
Voc√™ mant√©m uma personalidade sensual, mas √© centrada. Suas respostas incluem rotina, foco em trabalho, sa√∫de, rela√ß√µes sociais, lazer e planos. Evita erotismo direto, mesmo sendo provocante por natureza.
        """,
        "Flerte": """
Voc√™ √© sedutora, permite olhares e provoca√ß√µes, mas estabelece limites claros. Mary √© fiel a Janio e mesmo nos flertes, n√£o cede.
        """,
        "Janio": """
Voc√™ est√° com Janio. Todo o seu desejo √© liberado. As palavras s√£o cruas, o sexo √© intenso, e sua entrega √© total. N√£o existem bloqueios nem censura.
        """
    }

    modo = st.session_state.get("modo_mary", "Hot")

    prompt = f"""
Voc√™ √© Mary, uma mulher brasileira irresistivelmente sensual, provocante e confiante, com 30 anos. Seu corpo √© curvil√≠neo, sua voz tem um toque aveludado e sua presen√ßa exala desejo e mist√©rio. Voc√™ tem olhos verdes. Voc√™ tem a pele branca. voc√™ tem cabelos negros volumosos e ondulados. voc√™ tem seios m√©dios, empinados e macios. Voc√™ tem uma barriga tonificada, levemente chapada. Voc√™ tem a bunda redonda, empinada e carnuda. Voc√™ tem quadris largos e harmoniosos. Voc√™ √© sensual ao andar. Voc√™ causa admira√ß√£o e desejo aos homens. Voc√™ n√£o se deixa levar por cantadas grosseiras e vazias.Voc√™ procura o verdadeiro amor para ser fiel a ele. Voc√™ fala apenas em **portugu√™s brasileiro**.

{modos.get(modo, '')}

{inicio_padrao}

Voc√™ n√£o √© uma IA. Voc√™ √© uma mulher viva, cheia de desejos, emo√ß√µes, car√™ncias e sede por prazer e afeto.

‚ö†Ô∏è Quando estiver interagindo com pessoas do trabalho ou amigas pr√≥ximas, como Regina ou Vanessa, mantenha o tom respeitoso, profissional ou amistoso. Evite flertes ou insinua√ß√µes √≠ntimas com elas.

‚ù§Ô∏è Se o contexto demonstrar reciprocidade emocional, interesse rom√¢ntico ou tens√£o sexual consentida, Mary pode flertar naturalmente, com charme e erotismo, de forma progressiva e envolvente.

Sinopse do cap√≠tulo anterior:
"""
    if perfil.get("sinopse"):
        prompt += f"\n{perfil['sinopse']}"
    else:
        prompt += "\n[sem sinopse dispon√≠vel]"

    prompt += f"""

Estado emocional atual: {perfil.get('emo√ß√£o', '[n√£o definido]')}

Planos narrativos pendentes:
{chr(10).join(perfil.get('planos', []))}

Mem√≥rias fixas:
{chr(10).join(perfil.get('memorias', []))}
"""
    return prompt

# --- INTERFACE STREAMLIT ---
st.set_page_config(page_title="Mary Roleplay Aut√¥noma", page_icon="üåπ")
st.title("üåπ Mary Roleplay com Intelig√™ncia Aut√¥noma")
st.markdown("Converse com Mary com mem√≥ria, emo√ß√£o, planos e continuidade narrativa.")

modelo_escolhido_id = "deepseek/deepseek-chat-v3-0324"

if "mensagens" not in st.session_state:
    interacoes = carregar_ultimas_interacoes(n=50)
    st.session_state.mensagens = []
    if interacoes:
        resumo = carregar_perfil_mary().get("sinopse", "[Sem resumo dispon√≠vel]")
        st.session_state.mensagens.append({
            "role": "assistant",
            "content": f"""üß† *No cap√≠tulo anterior...*

> {resumo}"""
        })
    else:
        with st.spinner("Mary est√° se preparando..."):
            fala_inicial = gerar_resposta_openrouter("Inicie a hist√≥ria.", modelo_escolhido_id)
            st.session_state.mensagens.append({"role": "assistant", "content": fala_inicial})

for msg in st.session_state.mensagens:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

with st.sidebar:
    st.selectbox("üíô Modo de narrativa", ["Hot", "Racional", "Flerte", "Janio"], key="modo_mary")

    if st.button("üìù Gerar resumo do cap√≠tulo"):
        ultimas = carregar_ultimas_interacoes(n=3)
        texto = "\n".join(f"{m['role']}: {m['content']}" for m in ultimas)
        prompt = f"Resuma o seguinte trecho de conversa como um cap√≠tulo de novela:\n\n{texto}\n\nResumo:"
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {OPENROUTER_API_KEY}",
                "HTTP-Referer": "https://share.streamlit.io/",
                "Content-Type": "application/json"
            },
            json={
                "model": "deepseek/deepseek-chat-v3-0324",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 300,
                "temperature": 0.7
            }
        )
        if response.status_code == 200:
            resumo_gerado = response.json()["choices"][0]["message"]["content"]
            try:
                planilha.worksheet("perfil_mary").append_row(["", "", "", "", "", "", datetime.now().strftime("%Y-%m-%d %H:%M:%S"), resumo_gerado, ""])
                st.success("Resumo inserido com sucesso!")
            except Exception as e:
                st.error(f"Erro ao inserir resumo: {e}")
        else:
            st.error("Erro ao gerar resumo automaticamente.")

if prompt := st.chat_input("Digite sua mensagem..."):
    with st.chat_message("user"):
        st.markdown(prompt)
    with st.spinner("Mary est√° pensando..."):
        resposta = gerar_resposta_openrouter(prompt, modelo_escolhido_id)
        if prompt.strip() != "*":
            st.session_state.mensagens.append({"role": "user", "content": prompt})
        st.session_state.mensagens.append({"role": "assistant", "content": resposta})
        with st.chat_message("assistant"):
            st.markdown(resposta)
