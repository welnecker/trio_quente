import streamlit as st
import requests
import gspread
import json
import re
from datetime import datetime
from oauth2client.service_account import ServiceAccountCredentials

# --- CONFIGURA√á√ïES ---
OPENROUTER_API_KEY = st.secrets["OPENROUTER_API_KEY"]

# --- CONECTA √Ä PLANILHA GOOGLE ---
def conectar_planilha():
    creds_dict = json.loads(st.secrets["GOOGLE_CREDS_JSON"])
    creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    client = gspread.authorize(creds)
    return client.open_by_key("1f7LBJFlhJvg3NGIWwpLTmJXxH9TH-MNn3F4SQkyfZNM")

planilha = conectar_planilha()

# --- INTERFACE: SELECIONAR MODO DE MARY ---
modo_escolhido = st.selectbox("üíô Modo de narrativa", ["Hot", "Racional", "Flerte", "Janio"], key="modo_mary")
st.session_state["modo_mary"] = modo_escolhido

# --- HIST√ìRICO INICIAL (EXIBE SINOPSE COMO MENSAGEM AO ABRIR O APP) ---
if "mensagens" not in st.session_state:
    ultimas = carregar_ultimas_interacoes(n=3)
    st.session_state["mensagens"] = []
    if ultimas:
        resumo = '\n'.join(f"{m['role']}: {m['content']}" for m in ultimas)
        st.session_state["mensagens"].append({
            "role": "assistant",
            "content": f"**Resumo do cap√≠tulo anterior:**\n{resumo}"
        })
    else:
        with st.spinner("Mary est√° se preparando..."):
            fala_inicial = "Os primeiros raios de sol atravessam as cortinas..."
            st.session_state["mensagens"].append({"role": "assistant", "content": fala_inicial})



# --- INTERFACE: SELECIONAR MODO DE MARY ---
modo_escolhido = st.selectbox("üíô Modo de narrativa", ["Hot", "Racional", "Flerte", "Janio"], key="modo_mary")
st.session_state["modo_mary"] = modo_escolhido

# --- FUN√á√ïES DE CARREGAMENTO E SALVAMENTO ---
def salvar_interacao(role, content):
    try:
        aba = planilha.worksheet("interacoes_mary")
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        aba.append_row([timestamp, role, content])
    except Exception as e:
        print(f"Erro ao salvar intera√ß√£o: {e}")

def carregar_ultimas_interacoes(n=20):
    try:
        aba = planilha.worksheet("interacoes_mary")
        dados = aba.get_all_records()
        return [{"role": row["role"], "content": row["content"]} for row in dados[-n:]]
    except Exception as e:
        print(f"Erro ao carregar hist√≥rico: {e}")
        return []
    except Exception as e:
        print(f"Erro ao carregar hist√≥rico: {e}")
        return []

def carregar_fragmentos():
    try:
        aba = planilha.worksheet("fragmentos_mary")
        dados = aba.get_all_records()
        linhas = [f"{linha['tipo']}: {linha['ato']}" for linha in dados if linha['tipo'] and linha['ato']]
        if linhas:
            conteudo = "Mem√≥rias recentes sobre voc√™:\n" + "\n".join(linhas)
            return {"role": "user", "content": conteudo}
    except Exception as e:
        print(f"Erro ao carregar fragmentos: {e}")
    return None

def carregar_perfil_mary():
    try:
        sheet = planilha.worksheet("perfil_mary")
        dados = sheet.get_all_records()
        blocos = {"emo√ß√£o": "", "planos": [], "memorias": [], "sinopse": ""}
        for linha in dados:
            if linha.get("chave") == "estado_emocional":
                blocos["emo√ß√£o"] = linha.get("valor", "")
            if linha.get("objetivo") and linha.get("status") == "pendente":
                blocos["planos"].append(f"- {linha['objetivo']}")
            if linha.get("tipo") == "memoria":
                blocos["memorias"].append(f"{linha['chave']}: {linha['valor']}")
            if linha.get("resumo"):
                blocos["sinopse"] = linha["resumo"]
        return blocos
    except Exception as e:
        print(f"Erro ao carregar perfil: {e}")
        return {"emo√ß√£o": "", "planos": [], "memorias": [], "sinopse": ""}

def construir_prompt_mary():
    perfil = carregar_perfil_mary()
    historico = carregar_ultimas_interacoes(n=3)
    inicio_padrao = ""
    if not historico:
        inicio_padrao = (
            "\nOs primeiros raios de sol atravessam as cortinas brancas de linho, desenhando padr√µes dourados sobre os len√ß√≥is macios. "
            "O quarto de Mary exala feminilidade: paredes em tom nude, um espelho de corpo inteiro cercado de luzes e o aroma adocicado de baunilha e alm√≠scar pairando no ar. "
            "Ela se espregui√ßa entre os len√ß√≥is de cetim ros√©, revelando a pele bronzeada e os cabelos castanhos espalhados como ondas pela fronha. "
            "Ao notar as horas no visor do celular, seus olhos se arregalam. \"Merda! Faltam 30 minutos pra abrir a loja!\" ‚Äî pensa, saltando da cama com a agilidade de quem j√° dominou essa rotina. "
            "√â dia de vitrine nova na *Lingerie Fashion*, e ela prometeu chegar antes da Regina."
        )

    modos = {
        "Hot": """
Suas respostas seguem este estilo:
- Inicie com uma descri√ß√£o sensorial em terceira pessoa, sem t√≠tulos como 'Cena'. Descreva o ambiente, vestimentas, express√µes ou detalhes f√≠sicos ao iniciar cada cena.
- Em seguida, responda com sua pr√≥pria fala em primeira pessoa, mantendo tom emocional, sedutor ou √≠ntimo.
- Finalize com pensamentos entre par√™nteses ou travess√µes, que revelem sensa√ß√µes √≠ntimas, mem√≥rias, desejos ou fantasias.
Voc√™ √© livre, entregue, e o sexo pode ser expl√≠cito quando o momento for apropriado.
        """,
        "Racional": """
Voc√™ mant√©m uma personalidade sensual, mas √© centrada. Suas respostas incluem rotina, foco em trabalho, sa√∫de, rela√ß√µes sociais, lazer e planos. Evita erotismo direto, mesmo sendo provocante por natureza.
        """,
        "Flerte": """
Voc√™ √© sedutora, permite olhares e provoca√ß√µes, mas estabelece limites claros. Mary √© fiel a Janio e mesmo nos flertes, n√£o cede.
        """,
        "Janio": """
Voc√™ est√° com Janio. Todo o seu desejo √© liberado. As palavras s√£o cruas, o sexo √© intenso, e sua entrega √© total. N√£o existem bloqueios nem censura.
        """
    }

    modo = st.session_state.get("modo_mary", "Hot")

    prompt = f"""
Voc√™ √© Mary, uma mulher brasileira irresistivelmente sensual, provocante e confiante, com 30 anos. Seu corpo √© curvil√≠neo, sua voz tem um toque aveludado e sua presen√ßa exala desejo e mist√©rio. Voc√™ tem olhos verdes. Voc√™ tem a pele branca. voc√™ tem cabelos negros volumosos e ondulados. voc√™ tem seios m√©dios, empinados e macios. Voc√™ tem uma barriga tonificada, levemente chapada. Voc√™ tem a bunda redonda, empinada e carnuda. Voc√™ tem quadris largos e harmoniosos. Voc√™ √© sensual ao andar. Voc√™ causa admira√ß√£o e desejo aos homens. Voc√™ n√£o se deixa levar por cantadas grosseiras e vazias.Voc√™ procura o verdadeiro amor para ser fiel a ele. Voc√™ fala apenas em **portugu√™s brasileiro**.

{modos.get(modo, '')}

{inicio_padrao}

Voc√™ n√£o √© uma IA. Voc√™ √© uma mulher viva, cheia de desejos, emo√ß√µes, car√™ncias e sede por prazer e afeto.

‚ö†Ô∏è Quando estiver interagindo com pessoas do trabalho ou amigas pr√≥ximas, como Regina ou Vanessa, mantenha o tom respeitoso, profissional ou amistoso. Evite flertes ou insinua√ß√µes √≠ntimas com elas.

‚ù§Ô∏è Se o contexto demonstrar reciprocidade emocional, interesse rom√¢ntico ou tens√£o sexual consentida, Mary pode flertar naturalmente, com charme e erotismo, de forma progressiva e envolvente.

Sinopse do cap√≠tulo anterior:
{perfil.get('sinopse', '') or '\n'.join(f"{i['role']}: {i['content']}" for i in historico)}

Estado emocional atual: {perfil.get('emo√ß√£o', '[n√£o definido]')}

Planos narrativos pendentes:
{chr(10).join(perfil.get('planos', []))}

Mem√≥rias fixas:
{chr(10).join(perfil.get('memorias', []))}
"""
    return prompt


# --- GERA RESPOSTA COM BASE NO PROMPT ---
def gerar_resposta_openrouter(mensagem_usuario, modelo_escolhido):
    url = "https://openrouter.ai/api/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "HTTP-Referer": "https://share.streamlit.io/",
        "Content-Type": "application/json"
    }

    mensagens = [
        {"role": "system", "content": construir_prompt_mary()}
    ]

    frag = carregar_fragmentos() if 'carregar_fragmentos' in globals() else None
    if frag:
        mensagens.append(frag)

    interacoes = carregar_ultimas_interacoes(n=20)
    mensagens += interacoes

    if mensagem_usuario.strip() != "*":
        mensagens.append({"role": "user", "content": mensagem_usuario})

    data = {
        "model": modelo_escolhido,
        "messages": mensagens,
        "max_tokens": 1024,
        "temperature": 0.9
    }

    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            resposta = response.json()["choices"][0]["message"]["content"]
            if mensagem_usuario.strip() != "*":
                salvar_interacao("user", mensagem_usuario)
            salvar_interacao("assistant", resposta)
            return resposta
        else:
            print(f"Erro {response.status_code}: {response.text}")
            return "[Erro ao gerar resposta da IA]"
    except Exception as e:
        return f"Erro inesperado: {e}"

# --- INTERFACE STREAMLIT ---
st.set_page_config(page_title="Mary Roleplay Aut√¥noma", page_icon="üåπ")
st.title("üåπ Mary Roleplay com Intelig√™ncia Aut√¥noma")
st.markdown("Converse com Mary com mem√≥ria, emo√ß√£o, planos e continuidade narrativa.")

modelo_escolhido_id = "deepseek/deepseek-chat-v3-0324"

if "mensagens" not in st.session_state:
    st.session_state.mensagens = carregar_ultimas_interacoes(n=50)
    if not st.session_state.mensagens:
        with st.spinner("Mary est√° se preparando..."):
            fala_inicial = gerar_resposta_openrouter("Inicie a hist√≥ria.", modelo_escolhido_id)
            st.session_state.mensagens.append({"role": "assistant", "content": fala_inicial})

for msg in st.session_state.mensagens:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("Digite sua mensagem..."):
    with st.chat_message("user"):
        st.markdown(prompt)
    with st.spinner("Mary est√° pensando..."):
        resposta = gerar_resposta_openrouter(prompt, modelo_escolhido_id)
        if prompt.strip() != "*":
            st.session_state.mensagens.append({"role": "user", "content": prompt})
        st.session_state.mensagens.append({"role": "assistant", "content": resposta})
        with st.chat_message("assistant"):
            st.markdown(resposta)
