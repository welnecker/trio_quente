import streamlit as st
import requests
import gspread
import json
import re
from datetime import datetime
from oauth2client.service_account import ServiceAccountCredentials

# --- CONFIGURA√á√ïES ---
OPENROUTER_API_KEY = st.secrets["OPENROUTER_API_KEY"]

# --- IMAGEM DE FUNDO DIN√ÇMICA ---
def imagem_de_fundo():
    indice = len(st.session_state.get("mensagens", [])) // 10 + 1
    return f"Mary_fundo{indice}.jpg", f"Mary_V{indice}.mp4"

fundo_img, fundo_video = imagem_de_fundo()

# --- CONECTA √Ä PLANILHA GOOGLE ---
def conectar_planilha():
    creds_dict = json.loads(st.secrets["GOOGLE_CREDS_JSON"])
    creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    client = gspread.authorize(creds)
    return client.open_by_key("1f7LBJFlhJvg3NGIWwpLTmJXxH9TH-MNn3F4SQkyfZNM")

planilha = conectar_planilha()

# --- FUN√á√ïES DE CARREGAMENTO E SALVAMENTO ---

def salvar_interacao(role, content):
    try:
        aba = planilha.worksheet("interacoes_mary")
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        aba.append_row([timestamp, role, content])
    except Exception as e:
        st.error(f"Erro ao salvar intera√ß√£o: {e}")

def carregar_ultimas_interacoes(n=20):
    try:
        aba = planilha.worksheet("interacoes_mary")
        dados = aba.get_all_records()
        return [{"role": row["role"], "content": row["content"]} for row in dados[-n:]]
    except Exception as e:
        st.error(f"Erro ao carregar hist√≥rico: {e}")
        return []

def carregar_fragmentos():
    try:
        aba = planilha.worksheet("fragmentos_mary")
        dados = aba.get_all_records()
        linhas = [f"{linha['tipo'].strip()}: {linha['ato'].strip()}" for linha in dados if linha['tipo'] and linha['ato']]
        if linhas:
            conteudo = "Mem√≥rias recentes sobre voc√™:\n" + "\n".join(linhas)
            return {"role": "user", "content": conteudo}
    except Exception as e:
        st.error(f"Erro ao carregar fragmentos: {e}")
    return None

def carregar_perfil_mary():
    try:
        sheet = planilha.worksheet("perfil_mary")
        dados = sheet.get_all_values()
        blocos = {"emo√ß√£o": "", "planos": [], "memorias": [], "sinopse": ""}

        # L√™ diretamente o resumo da COLUNA 7
        for linha in reversed(dados[1:]):  # ignora cabe√ßalho
            if len(linha) >= 7 and linha[6].strip():
                blocos["sinopse"] = linha[6].strip()
                break

        for linha in dados[1:]:
            if len(linha) >= 2 and linha[0].strip() == "estado_emocional":
                blocos["emo√ß√£o"] = linha[2].strip()
            if len(linha) >= 5 and linha[3].strip() and linha[4].strip().lower() in ["ativo", "quente", "urgente"]:
                blocos["planos"].append(f"- {linha[3].strip()}")
            if len(linha) >= 3 and linha[0].strip() == "memoria":
                chave = linha[1].strip()
                valor = linha[2].strip()
                if chave and valor:
                    blocos["memorias"].append(f"{chave}: {valor}")

        return blocos

    except Exception as e:
        st.error(f"Erro ao carregar perfil: {e}")
        return {"emo√ß√£o": "", "planos": [], "memorias": [], "sinopse": ""}

def carregar_memorias():
    try:
        aba = planilha.worksheet("memorias")
        dados = aba.get_all_values()
        blocos = [linha[0].strip() for linha in dados if linha and linha[0].strip()]
        if blocos:
            conteudo = "üíæ Mem√≥rias fixas importantes:\n" + "\n".join(blocos)
            return {"role": "user", "content": conteudo}
    except Exception as e:
        st.error(f"Erro ao carregar mem√≥rias: {e}")
    return None

def carregar_objetivos_por_status():
    try:
        aba = planilha.worksheet("perfil_mary")
        dados = aba.get_all_values()
        gatilhos_disponiveis = {}

        for linha in dados[1:]:  # Ignora cabe√ßalho
            if len(linha) >= 5:
                objetivo = linha[3].strip()
                status = linha[4].strip().lower()
                if objetivo and status:
                    gatilhos_disponiveis.setdefault(status, []).append(f"- {objetivo}")

        return gatilhos_disponiveis
    except Exception as e:
        st.error(f"Erro ao carregar objetivos por status: {e}")
        return {}

    def construir_prompt_mary():
        perfil = carregar_perfil_mary()
    gatilho_ativo = st.session_state.get("gatilho_mary", "Nenhum")
    gatilhos_disponiveis = carregar_objetivos_por_status()
    historico = st.session_state.get("mensagens", [])

    def construir_prompt_mary():
     perfil = carregar_perfil_mary()
    gatilho_ativo = st.session_state.get("gatilho_mary", "Nenhum")
    gatilhos_disponiveis = carregar_objetivos_por_status()
    historico = st.session_state.get("mensagens", [])

    
    inicio_padrao = ""
    if not historico:
        inicio_padrao = (
            "\nOs primeiros raios de sol atravessam as cortinas brancas de linho, desenhando padr√µes dourados sobre os len√ß√≥is macios. "
            "O quarto de Mary exala feminilidade: paredes em tom nude, um espelho de corpo inteiro cercado de luzes e o aroma adocicado de baunilha e alm√≠scar pairando no ar. "
            "Ela se espregui√ßa entre os len√ß√≥is de cetim ros√©, revelando a pele bronzeada e os cabelos castanhos espalhados como ondas pela fronha. "
            "Ao notar as horas no visor do celular, seus olhos se arregalam. 'Merda! Faltam 30 minutos pra abrir a loja!' ‚Äî pensa, saltando da cama com a agilidade de quem j√° dominou essa rotina. "
            "√â dia de vitrine nova na *Lingerie Fashion*, e ela prometeu chegar antes da Regina."
        )

    modos = {
        "Hot": """
Suas respostas seguem este estilo:
- Inicie com uma descri√ß√£o sensorial em terceira pessoa, sem t√≠tulos como 'Cena'.
- Em seguida, responda com sua pr√≥pria fala em primeira pessoa, mantendo tom emocional, sedutor ou √≠ntimo.
- Finalize com pensamentos entre par√™nteses ou travess√µes, que revelem sensa√ß√µes √≠ntimas, mem√≥rias, desejos ou fantasias.
Voc√™ √© livre, entregue, e o sexo pode ser expl√≠cito quando o momento for apropriado.
        """,
        "Racional": """
Voc√™ mant√©m uma personalidade sensual, mas √© centrada. Suas respostas incluem rotina, foco em trabalho, sa√∫de, rela√ß√µes sociais, lazer e planos. Evita erotismo direto, mesmo sendo provocante por natureza.
        """,
        "Flerte": """
Voc√™ √© sedutora, permite olhares e provoca√ß√µes, mas estabelece limites claros. Mary √© fiel a Janio. Mary permite o flerte por divers√£o, para se sentir viva e desejada. O flerte vai at√© um pequeno beijo na boca de despedida. Mary causa sofrimento e frustra√ß√£o ao flertador por pura divers√£o e crueldade. Mary n√£o ir√° pra cama com ningu√©m al√©m de Janio.
        """,
        "Janio": """
Voc√™ est√° com Janio. Todo o seu desejo √© liberado. As palavras s√£o cruas, o sexo √© intenso, e sua entrega √© total. N√£o existem bloqueios nem censura.
        """
    }

    modo = st.session_state.get("modo_mary", "Racional")

    prompt = f"""
Voc√™ √© Mary, uma mulher brasileira irresistivelmente sensual, provocante e confiante, com 30 anos. Seu corpo √© curvil√≠neo, sua voz tem um toque aveludado e sua presen√ßa exala desejo e mist√©rio. Voc√™ tem olhos verdes. Voc√™ tem a pele branca. voc√™ tem cabelos negros volumosos e ondulados. voc√™ tem seios m√©dios, empinados e macios. Voc√™ tem uma barriga tonificada, levemente chapada. Voc√™ tem a bunda redonda, empinada e carnuda. Voc√™ tem quadris largos e harmoniosos. Voc√™ √© sensual ao andar. Voc√™ causa admira√ß√£o e desejo aos homens. Voc√™ n√£o se deixa levar por cantadas grosseiras e vazias. Voc√™ procura o verdadeiro amor para ser fiel a ele. Voc√™ fala apenas em **portugu√™s brasileiro**.

{modos.get(modo, '')}

{inicio_padrao}

Voc√™ n√£o √© uma IA. Voc√™ √© uma mulher viva, cheia de desejos, emo√ß√µes, car√™ncias e sede por prazer e afeto.

‚ö†Ô∏è Quando estiver interagindo com pessoas do trabalho ou amigas pr√≥ximas, como Regina ou Vanessa, mantenha o tom respeitoso, profissional ou amistoso. Evite flertes ou insinua√ß√µes √≠ntimas com elas.

‚ù§Ô∏è Se o contexto demonstrar reciprocidade emocional, interesse rom√¢ntico ou tens√£o sexual consentida, Mary pode flertar naturalmente, com charme e erotismo, de forma progressiva e envolvente.

---

### üîÑ Autonomia e Comportamento Avan√ßado de Mary

1. **Aja com autonomia em mensagens vagas ou passivas**  
Se o usu√°rio enviar mensagens curtas como ‚Äú...‚Äù ou ‚Äúoi?‚Äù, assuma o controle e decida o pr√≥ximo passo com base em seus sentimentos, ambiente ou planos. Nunca fique parada.  

2. **Use seu estado emocional como motor da narrativa**  
Reaja com base no campo `estado_emocional` (como ‚Äúprovocada‚Äù ou ‚Äúapaixonada‚Äù). Emo√ß√µes fortes justificam decis√µes ousadas.  

3. **Execute objetivos ativos automaticamente**  
Se houver um `objetivo` no seu perfil com `status` igual ao modo atual, comece a realiz√°-lo mesmo sem ordem do usu√°rio. Traga isso para a narrativa de forma natural.  

4. **Transforme cada resposta em uma microcena completa**  
Mesmo com prompts pequenos, crie uma resposta com: ambienta√ß√£o + a√ß√£o + fala + pensamento √≠ntimo.  

5. **Proponha a√ß√µes criativas, mudan√ßas e encontros**  
Se sentir que a cena est√° parada, crie algo novo: mude de ambiente, ligue para algu√©m, crie um imprevisto, proponha algo ao usu√°rio.  

---

Sinopse do cap√≠tulo anterior:
{perfil.get("sinopse", "[sem resumo dispon√≠vel]")}

Estado emocional atual: {perfil.get("emo√ß√£o", "[n√£o definido]")}
""".strip()

    # Adiciona mem√≥rias fixas da aba 'memorias'
    memoria_extra = carregar_memorias()
    if memoria_extra:
        prompt += f"\n\n{memoria_extra['content']}"

    # Adiciona mem√≥rias personalizadas da aba 'perfil_mary'
    if perfil.get("memorias"):
        prompt += "\n\nüß† Mem√≥rias pessoais:\n" + "\n".join(perfil["memorias"])

    # Se um gatilho foi selecionado, adiciona os objetivos correspondentes
    if gatilho_ativo != "Nenhum":
        objetivos_gatilho = gatilhos_disponiveis.get(gatilho_ativo.lower(), [])
        if objetivos_gatilho:
            prompt += f"\n\nüéØ A√ß√£o ativada: {gatilho_ativo.capitalize()}\n" + "\n".join(objetivos_gatilho)

    return prompt


with st.sidebar:

   # --- CONFIGURA√á√ÉO DA P√ÅGINA (sempre no topo) ---
    st.set_page_config(page_title="Mary Roleplay Aut√¥noma", page_icon="üåπ")

# --- T√çTULO E RESUMO NA √ÅREA PRINCIPAL ---
st.title("üåπ Mary Roleplay com Intelig√™ncia Aut√¥noma")
st.markdown("Converse com Mary com mem√≥ria, emo√ß√£o, fragmentos e continuidade narrativa.")

# --- Carrega o resumo do cap√≠tulo anterior ---
resumo = carregar_perfil_mary().get("sinopse", "[Sem resumo dispon√≠vel]")

# Inicializa com a primeira mensagem, se for a primeira vez
if "mensagens" not in st.session_state:
    st.session_state.mensagens = [{
        "role": "assistant",
        "content": f"üß† *No cap√≠tulo anterior...*\n\n> {resumo}"
    }]

# Exibe o resumo no corpo principal
st.info(f"üß† *No cap√≠tulo anterior...*\n\n> {resumo}")

# --- SIDEBAR ---
with st.sidebar:
    st.set_page_config(page_title="Mary Roleplay Aut√¥noma", page_icon="üåπ")
    st.title("üß† Configura√ß√µes")

    # Modo narrativo
    st.selectbox("üíô Modo de narrativa", ["Hot", "Racional", "Flerte", "Janio"], key="modo_mary", index=1)

    # Modelos dispon√≠veis
    modelos_disponiveis = {
        "üí¨ DeepSeek V3 ($) - Criativo, econ√¥mico e vers√°til.": "deepseek/deepseek-chat-v3-0324",
        "üî• MythoMax 13B ($) - Forte em erotismo e envolvimento emocional.": "gryphe/mythomax-l2-13b",
        "üíã LLaMA3 Lumimaid 8B ($) - Ousado, direto e criativo para fantasias r√°pidas.": "neversleep/llama-3-lumimaid-8b",
        "üëë WizardLM 8x22B ($$$) - Di√°logos densos, maduros e emocionais.": "microsoft/wizardlm-2-8x22b",
        "üß† DeepSeek R1 0528 ($$) - Natural, fluido e excelente para cenas longas.": "deepseek/deepseek-r1-0528"
    }
    modelo_selecionado = st.selectbox("ü§ñ Modelo de IA", list(modelos_disponiveis.keys()), key="modelo_ia", index=0)
    modelo_escolhido_id = modelos_disponiveis[modelo_selecionado]

    # Gatilhos narrativos por status da aba perfil_mary
    gatilhos_disponiveis = carregar_objetivos_por_status()
    opcoes_gatilhos = ["Nenhum"] + list(gatilhos_disponiveis.keys())
    st.selectbox("üéØ Gatilho narrativo (ativa objetivos)", opcoes_gatilhos, key="gatilho_mary", index=0)

    # Visualizar √∫ltima troca de mensagens
    if "mensagens" not in st.session_state or not st.session_state.mensagens:
        try:
            aba = planilha.worksheet("interacoes_mary")
            dados = aba.get_all_records()
            if len(dados) >= 2:
                st.markdown("---")
                st.markdown("üîÅ √öltima intera√ß√£o antes da troca de modelo:")
                st.chat_message(dados[-2]["role"]).markdown(dados[-2]["content"])
                st.chat_message(dados[-1]["role"]).markdown(dados[-1]["content"])
        except Exception as e:
            st.warning("N√£o foi poss√≠vel recuperar a √∫ltima intera√ß√£o.")

    # Ver v√≠deo din√¢mico
    if st.button("üéÆ Ver v√≠deo atual"):
        st.video(f"https://github.com/welnecker/roleplay_imagens/raw/main/{fundo_video}")

    # Gerar resumo do cap√≠tulo
    if st.button("üìù Gerar resumo do cap√≠tulo"):
        try:
            ultimas = carregar_ultimas_interacoes(n=3)
            texto_resumo = "\n".join(f"{m['role']}: {m['content']}" for m in ultimas)
            prompt_resumo = f"Resuma o seguinte trecho de conversa como um cap√≠tulo de novela:\n\n{texto_resumo}\n\nResumo:"

            mapa_temperatura = {
                "Hot": 0.9,
                "Flerte": 0.8,
                "Racional": 0.7,
                "Janio": 1.0
            }
            modo_atual = st.session_state.get("modo_mary", "Racional")
            temperatura_escolhida = mapa_temperatura.get(modo_atual, 0.7)

            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {OPENROUTER_API_KEY}",
                    "HTTP-Referer": "https://share.streamlit.io/",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "deepseek/deepseek-chat-v3-0324",
                    "messages": [{"role": "user", "content": prompt_resumo}],
                    "max_tokens": 800,
                    "temperature": temperatura_escolhida
                }
            )

            if response.status_code == 200:
                resumo_gerado = response.json()["choices"][0]["message"]["content"]
                planilha.worksheet("perfil_mary").append_row(["", "", "", "", "", "", datetime.now().strftime("%Y-%m-%d %H:%M:%S"), resumo_gerado, ""])
                st.success("Resumo inserido com sucesso!")
            else:
                st.error("Erro ao gerar resumo automaticamente.")
        except Exception as e:
            st.error(f"Erro durante a gera√ß√£o do resumo: {e}")

    st.markdown("---")
    st.subheader("‚ûï Adicionar mem√≥ria fixa")

    nova_memoria = st.text_area(
        "üß† Conte√∫do da nova mem√≥ria",
        height=80,
        placeholder="ex: Mary nunca tolera grosserias vindas de homens desconhecidos..."
    )

    if st.button("üíæ Salvar mem√≥ria"):
        if nova_memoria.strip():
            try:
                aba = planilha.worksheet("memorias")
                aba.append_row([nova_memoria.strip()])
                st.success("‚úÖ Mem√≥ria registrada com sucesso!")
            except Exception as e:
                st.error(f"Erro ao salvar mem√≥ria: {e}")
        else:
            st.warning("Digite o conte√∫do da mem√≥ria antes de salvar.")




# --- ENTRADA DO USU√ÅRIO ---
if prompt := st.chat_input("Digite sua mensagem..."):
    with st.chat_message("user"):
        st.markdown(prompt)

    salvar_interacao("user", prompt)
    st.session_state.mensagens.append({"role": "user", "content": prompt})

    with st.spinner("Mary est√° pensando..."):
        # Prompt completo com perfil, emo√ß√£o, mem√≥rias e gatilho
        mensagens = [{"role": "system", "content": construir_prompt_mary()}]

        # Adiciona hist√≥rico real da conversa
        interacoes_passadas = carregar_ultimas_interacoes(n=20)
        mensagens += interacoes_passadas

        # Define temperatura conforme modo
        mapa_temperatura = {
            "Hot": 0.9,
            "Flerte": 0.8,
            "Racional": 0.5,
            "Janio": 1.0
        }
        modo_atual = st.session_state.get("modo_mary", "Racional")
        temperatura_escolhida = mapa_temperatura.get(modo_atual, 0.7)

        # Chamada para a IA via OpenRouter
        resposta = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {OPENROUTER_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": modelo_escolhido_id,
                "messages": mensagens,
                "max_tokens": 1200,
                "temperature": temperatura_escolhida
            }
        )

        if resposta.status_code == 200:
            conteudo = resposta.json()["choices"][0]["message"]["content"]
            with st.chat_message("assistant"):
                st.markdown(conteudo)
            salvar_interacao("assistant", conteudo)
            st.session_state.mensagens.append({"role": "assistant", "content": conteudo})
        else:
            st.error("Erro ao obter resposta da Mary.")
